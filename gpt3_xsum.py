# -*- coding: utf-8 -*-
"""GPT3_XSUM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rGCSNCothWsVR-YRmgcNE0EuxtpsTqws
"""

import openai
from datasets import load_dataset
from rouge_score import rouge_scorer

# Set your OpenAI API key here
openai.api_key = '661d60ea-8cf1-4850-b9cd-ff8ff38bb225'

# Load dataset
dataset = load_dataset("xsum")
val_data = dataset["validation"]

# Function to generate summaries using GPT-3
def generate_summary(text, model="gpt-3.5-turbo"):
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": f"Summarize the following text: {text}"}
        ]
    )
    summary = response.choices[0].message["content"].strip()
    return summary

# Evaluate ROUGE scores
def compute_rouge(predictions, references):
    scorer = rouge_scorer.RougeScorer(["rouge1", "rouge2", "rougeL"], use_stemmer=True)
    scores = {"rouge1": 0, "rouge2": 0, "rougeL": 0}
    num_predictions = len(predictions)

    for pred, ref in zip(predictions, references):
        score = scorer.score(ref, pred)
        for key in scores:
            scores[key] += score[key].fmeasure

    return {key: value / num_predictions for key, value in scores.items()}

# Generate summaries and compute ROUGE scores
predictions = []
references = val_data["summary"]

for example in val_data:
    document = example["document"]
    summary = generate_summary(document)
    predictions.append(summary)

# Compute ROUGE scores
rouge_scores = compute_rouge(predictions, references)
print("ROUGE Scores:", rouge_scores)